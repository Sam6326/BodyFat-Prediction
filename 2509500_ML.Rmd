---
title: "Machine Learning Prediction"
author: "Sampath Kumar Gollapalli Ramana Murthy"
date: "2025-04-09"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
install package 
```{r}
install.packages("tidyverse")
```
Load libraries
```{r}
library(tidyverse)
library(dplyr)
```

1. Cleaning the data
```{r}
# read the data from the csv file
bodyfat_data <- read.csv("Raw_Data.csv", header = TRUE)

# check for missing values
missing_summary <- colSums(is.na(bodyfat_data))
print(missing_summary)

# check data types
bodyfat_data <- bodyfat_data %>%
  mutate(across(everything(), as.numeric))

# Remove specific outliers
# Removing row with Weight = 363.15 lbs (row 39)
# Removing row with BodyFat = 47.5% (row 182)
bodyfat_data <- bodyfat_data %>%
  filter(Weight != 363.15 & BodyFat != 47.5)

# Correcting obvious errors
# Fixing Height anomaly (29.50 -> 69.50)
bodyfat_data$Height[bodyfat_data$Height == 29.50] <- 69.50

# Check for duplicates
duplicates <- duplicated(bodyfat_data)

print(sum(duplicates))

# Remove duplicates if any
bodyfat_data <- bodyfat_data[!duplicates, ]

# Validate body measurements 
measurement_cols <- c("Neck", "Chest", "Abdomen", "Hip", "Thigh", "Knee", "Ankle", "Biceps", "Forearm", "Wrist")
negatives <- bodyfat_data %>%
  select(all_of(measurement_cols)) %>%
  summarise(across(everything(), ~sum(. < 0)))
print(negatives)

# Replace negatives with NA 
bodyfat_data <- bodyfat_data %>%
  mutate(across(all_of(measurement_cols), ~ifelse(. < 0, NA, .)))

str(bodyfat_data)

# Removing the additional outliers using IQR method (Source: 2)
cols_to_check <- c("Weight", "Neck", "Chest", "Abdomen", "Hip", "Thigh", "Knee", "Ankle", "Forearm", "Wrist")

# Function to identify outlier rows across all columns
remove_outliers_iterative <- function(data, columns) {
  repeat {
    outlier_flags <- rep(FALSE, nrow(data))
    for (col in columns) {
      q <- quantile(data[[col]], c(0.25, 0.75), na.rm = TRUE)
      iqr <- IQR(data[[col]], na.rm = TRUE)
      lower <- q[1] - 1.5 * iqr
      upper <- q[2] + 1.5 * iqr
      outlier_flags <- outlier_flags | (data[[col]] < lower | data[[col]] > upper)
    }
    if (!any(outlier_flags)) break
    data <- data[!outlier_flags, ]
  }
  return(data)
}

#  outlier removal
bodyfat_data <- remove_outliers_iterative(bodyfat_data, cols_to_check)

# checking for outliers with boxplot
par(mfrow = c(2, 5))  # 2x5 grid for multiple plots to view at once
for (col in cols_to_check) {
  boxplot(bodyfat_data[[col]], main = paste(col, "Boxplot"), ylab = col)
}
par(mfrow = c(1, 1))  # Note: Reset plot layout if you want to view polt for each and every column

str(bodyfat_data)

# Exporting the cleaned dataset
write.csv(bodyfat_data, "Data_Cleaned.csv", row.names = FALSE)
summary(Data_Cleaned)
```

2. Exploratory data analysis
```{r}
# load cleaned data from csv
bodyfat_cleaned <- read.csv("Data_Cleaned.csv")
bodyfat_eda <- bodyfat_cleaned[,-2]
# get summary report of variables
summary(bodyfat_eda)

# calculate pearson correlation coefficient
cor(bodyfat_eda)

# create histogram for each variable
hist(bodyfat_eda[, 1], main = names(bodyfat_eda)[1], xlab = names(bodyfat_eda)[1])
hist(bodyfat_eda[, 2], main = names(bodyfat_eda)[2], xlab = names(bodyfat_eda)[2])
hist(bodyfat_eda[, 3], main = names(bodyfat_eda)[3], xlab = names(bodyfat_eda)[3])
hist(bodyfat_eda[, 4], main = names(bodyfat_eda)[4], xlab = names(bodyfat_eda)[4])
hist(bodyfat_eda[, 5], main = names(bodyfat_eda)[5], xlab = names(bodyfat_eda)[5])
hist(bodyfat_eda[, 6], main = names(bodyfat_eda)[6], xlab = names(bodyfat_eda)[6])
hist(bodyfat_eda[, 7], main = names(bodyfat_eda)[7], xlab = names(bodyfat_eda)[7])
hist(bodyfat_eda[, 8], main = names(bodyfat_eda)[8], xlab = names(bodyfat_eda)[8])
hist(bodyfat_eda[, 9], main = names(bodyfat_eda)[9], xlab = names(bodyfat_eda)[9])
hist(bodyfat_eda[, 10], main = names(bodyfat_eda)[10], xlab = names(bodyfat_eda)[10])
hist(bodyfat_eda[, 11], main = names(bodyfat_eda)[11], xlab = names(bodyfat_eda)[11])
hist(bodyfat_eda[, 12], main = names(bodyfat_eda)[12], xlab = names(bodyfat_eda)[12])
hist(bodyfat_eda[, 13], main = names(bodyfat_eda)[13], xlab = names(bodyfat_eda)[13])
hist(bodyfat_eda[, 14], main = names(bodyfat_eda)[14], xlab = names(bodyfat_eda)[14])

```
Principal component analysis
```{r}
# perform pca
pca_bodyfat <- prcomp(bodyfat_eda, center = T, scale. = T)

# calculate the proportion of explained variance (PEV) from the std values
pca_bodyfat_var <- pca_bodyfat$sdev^2
pca_bodyfat_var
pca_bodyfat_PEV <- pca_bodyfat_var/sum(pca_bodyfat_var)
pca_bodyfat_PEV

# plot the variance per PC
plot(pca_bodyfat)

# plot the cumulative value of PEV for increasing number of additional PCs
png("bodyfat_plot_80.png", width = 600, height = 400)

opar <- par(no.readonly = TRUE)
plot(
  cumsum(pca_bodyfat_PEV),
  ylim = c(0,1),
  xlab = 'PC',
  ylab = 'cumulative PEV',
  pch = 20,
  col = 'orange'
)
abline(h = 0.8, col = 'red', lty = 'dashed')
par(opar)


# get and inspect the loadings for each PC
pca_bodyfat_loadings <- pca_bodyfat$rotation
pca_bodyfat_loadings

# plot the loadings for the first three PCs as a barplot
opar <- par(no.readonly = TRUE)
colvector = c('red', 'orange', 'yellow', 'green', 'cyan', 'blue')
labvector = c('PC1', 'PC2', 'PC3')
barplot(
  pca_bodyfat_loadings[,c(1:3)],
  beside = T,
  yaxt = 'n',
  names.arg = labvector,
  col = colvector,
  ylim = c(-1,1),
  border = 'white',
  ylab = 'loadings'
)
axis(2, seq(-1,1,0.1))
legend(
  'bottomright',
  bty = 'n',
  col = colvector,
  pch = 15,
  row.names(pca_bodyfat_loadings)
)
par(opar)

# generate a biplot for each pair of important PCs
opar <- par(no.readonly = TRUE)
par(mfrow = c(2,2))
biplot(
  pca_bodyfat,
  scale = 0,
  col = c('grey40','orange')
)
biplot(
  pca_bodyfat,
  choices = c(1,3),
  scale = 0,
  col = c('grey40','orange')
)
biplot(
  pca_bodyfat,
  choices = c(2,3),
  scale = 0,
  col = c('grey40','orange')
)
par(opar)

# subset data to include only variables from PCA

bodyfat_cleaned_pca <- bodyfat_cleaned[,1:4]

# Exporting the cleaned dataset
write.csv(bodyfat_cleaned_pca, "Data_EDA.csv", row.names = FALSE)

```
3. Neural network training

```{r}
# summary 
summary(bodyfat_cleaned_pca)

# data pre-processing
MinMax <- function(x){
  tx <- (x - min(x)) / (max(x) - min(x))
  return(tx)
}

bodyfat_minmax <- apply(bodyfat_cleaned_pca, 2, MinMax)

bodyfat_minmax <- as.data.frame(bodyfat_minmax)

# split data into training and test sets

n_rows <- nrow(bodyfat_minmax)

training_idx <- sample(n_rows,n_rows * 0.7)

training_bodyfat <- bodyfat_minmax[training_idx,]
test_bodyfat <- bodyfat_minmax[-training_idx,]

# define a formula for predicting bodyfat

bodyfat_formula <- BodyFat ~ Density + Age + Weight

# train neural network using one hidden layer with two nodes 

bodyfat_nn2 <- neuralnet::neuralnet(bodyfat_formula, hidden = c(2), data = training_bodyfat)

#plot each neural network
png("NN_plot_steps.png", width = 600, height = 400)

plot(bodyfat_nn2)


```
4. Neural network prediction
```{r}
# Compute predictions
pred_bodyfat_nn2 <- neuralnet::compute(bodyfat_nn2, test_bodyfat[,-2])

# Table with actual and predicted values
bodyfat_results <- data.frame(
  actual = test_bodyfat$BodyFat,
  nn_2 = pred_bodyfat_nn2$net.result
)

# Calculating RMSE and R-squared
rmse_nn_2 <- sqrt(mean((bodyfat_results$actual - bodyfat_results$nn_2)^2))
cat("RMSE (2 nodes):", rmse_nn_2, "\n")
r_squared_nn_2 <- cor(bodyfat_results$actual, bodyfat_results$nn_2)^2
cat("R-squared (2 nodes):", r_squared_nn_2, "\n")

# corrlation between actual vs predicted
cor(bodyfat_results[,'actual'], bodyfat_results[,c("nn_2")])

png("bodyfat_plot.png", width = 600, height = 400)

plot(
  bodyfat_results$actual,
  bodyfat_results$nn_2,
  col = 'blue',
  xlab = 'Actual BodyFat',
  ylab = 'Predicted BodyFat',
  main = paste("Actual BodyFat vs Predicted BodyFat\nRMSE:", round(rmse_nn_2, 4), ", RÂ²:", round(r_squared_nn_2, 4)),
  xlim = range(bodyfat_results$actual),
  ylim = range(bodyfat_results$nn_2)
)
abline(a = 0, b = 1, col = 'red', lty = 'dashed')
legend(
  'topleft',
  'nn_2',
  pch = 1,
  col = 'blue',
  bty = 'n'
)


```
